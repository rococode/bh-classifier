unique ids:
c15f9d29-4cbe-445d-90b5-e3c75ee99bef: [34909 , 25318 , 29553 , 89876 , 62449 ]
5b2eafe6-9b5c-404e-b61b-cc93ea53025a: [38703 , 79045 , 43602 , 39516 , 95006 ]
ac32669b-6140-4dcf-82bf-f4369f415f20: [38418 , 45503 , 49779 , 37223 , 24957 ]
a5b47276-5fa0-476e-9371-d2bd330619f7: [13884 , 72470 , 66192 , 82465 , 84706 ]
6307c15f-08ce-4281-9a3a-043ab7d988f9: [37805 , 39267 , 92873 , 88732 , 65909 ]
1b36cdb3-4fb1-4994-b87f-0353620c1271: [39788 , 33396 , 99799 , 43115 , 28979 ]
9aa28af0-7d15-4438-a278-657c93dda3d5: [30025 , 77527 , 52071 , 12431 , 40697 ]
1e82e91c-77df-412d-b581-176fb52ced8d: [83200 , 53266 , 17287 , 95197 , 68025 ]
8bd31b2e-3a12-4dcc-8692-f4a535bfcc15: [23386 , 31915 , 17834 , 57879 , 49456 ]
2433d69f-0ecc-4dd8-aca1-14432bf264bf: [45133 , 52936 , 71019 , 44084 , 33734 ]
912e14f1-2f16-459d-8d0c-e10a1027b6de: [77328 , 61361 , 95338 , 11006 , 98510 ]
e5acc83b-a65c-41c8-a3c0-0878dc8b0641: [43568 , 37310 , 53076 , 64001 , 11862 ]
14c5d42f-35d5-43ad-8526-a3b81fb5c259: [63223 , 17347 , 56442 , 87602 , 54186 ]
6c8f7eb6-a2a7-4cf2-b3ea-8e7cfeb9d549: [43613 , 59284 , 87517 , 29214 , 46085 ]
c099a88f-cece-458f-b127-1dc51ef12599: [17209 , 36508 , 16979 , 80236 , 76315 ]
861e5d5a-59d4-4709-a6db-27d8c9d11b05: [91801 , 35467 , 23404 , 17894 , 12449 ]
dfd4bde5-d355-4f6a-abe3-fb172580823f: [72760 , 62071 , 76494 , 51424 , 11009 ]
93b70965-f3ab-40e2-947a-5894735cf17a: [63547 , 86435 , 84802 , 76261 , 32602 ]
94d16d78-d10b-45e1-8a4c-0887a2f50271: [42636 , 56717 , 80642 , 94111 , 49098 ]
09cbf868-eed8-4e7c-8171-02ecaae79ea6: [48664 , 38032 , 23507 , 85310 , 45494 ]
9ff0bd96-960e-45e0-8e0e-39b27b3059a0: [84732 , 96710 , 56532 , 32944 , 46546 ]
f34b2227-7f4f-48ee-a324-554529f121e5: [97414 , 53668 , 78025 , 27825 , 55658 ]
30dd1b0d-b862-47ee-b4e7-86388df23c51: [30236 , 13134 , 53470 , 41163 , 21319 ]
0a07b803-8707-479c-8c05-50ea4673fa92: [39300 , 45589 , 90973 , 43152 , 52675 ]
2f1ec1b4-0534-45f6-9947-913083515b45: [17463 , 34160 , 49560 , 45664 , 45731 ]
15772021-6164-40e8-a6f4-a08309ca0c5e: [73280 , 39304 , 25582 , 53757 , 79023 ]
39dae4f4-8cd6-46c5-9a93-8f27168f2692: [71180 , 48113 , 28638 , 77764 , 86132 ]
2c26b600-9ebc-4598-b8bf-7264f3e04616: [17595 , 44933 , 89382 , 63416 , 78548 ]
6c53c5f5-b086-42cf-9529-f6fb1788820c: [85192 , 90130 , 52767 , 21687 , 18629 ]
63b358b8-58f8-47d9-a49e-df83246fcf8a: [80302 , 42208 , 42782 , 88743 , 20462 ]
06e3ecb8-8707-4a61-a93a-f9216079c148: [89329 , 66451 , 86047 , 10909 , 46894 ]
bae5e601-d75a-4344-97f2-1148f1d5dc37: [74192 , 74407 , 38915 , 62737 , 15560 ]
bee4b192-6e06-4d3c-ac03-664cce6c70f6: [46910 , 10900 , 13384 , 18415 , 62338 ]
0c4256b2-c8eb-4126-a776-612bdf00e80a: [90636 , 84509 , 85740 , 24546 , 16830 ]
69cce717-7e85-4767-8398-66ba8e4487c4: [32228 , 13522 , 20450 , 97775 , 94456 ]
45895ef8-c037-4be2-bbc7-77bf08cb163c: [45237 , 68888 , 52037 , 90178 , 12280 ]
283d6f0b-2abf-4271-93ba-7a37cd9733fe: [90718 , 75987 , 51173 , 90092 , 98178 ]
c61bae24-7b8c-47f3-bf26-88ccfdfb4f64: [33251 , 11935 , 35018 , 64366 , 21158 ]
2a035311-a655-47d0-85f9-f003a3bf32d7: [68374 , 43087 , 52623 , 35158 , 18125 ]
8d550ee0-4897-4c8f-a84e-610e91bc4174: [92831 , 87020 , 37944 , 99644 , 64859 ]
252a5804-e8b2-42b1-abe3-ca3db1ae9a52: [67214 , 73595 , 59029 , 43284 , 68112 ]
3fe3b475-e204-42ef-8222-3b2eca30419c: [37817 , 20260 , 24211 , 47433 , 77475 ]
3c94b9fd-fd20-49f4-b5e3-e9affdbf61d9: [97854 , 44731 , 63478 , 32748 , 57995 ]
ff915f66-d311-4cee-9b15-46f6f4ba8603: [95868 , 79444 , 58969 , 67333 , 60721 ]
13a25166-03af-4048-80f5-d6149b0876f6: [93181 , 29311 , 43323 , 68848 , 72025 ]
4203dda1-6deb-46de-92f4-4e5cd852ed38: [71990 , 55201 , 25937 , 21960 , 97245 ]
c560122e-0301-4e8d-8641-fff0b26d2831: [89937 , 82918 , 91452 , 56627 , 98006 ]
42386715-faf6-4a7b-a718-71dba0cf9072: [60065 , 25483 , 98702 , 77716 , 67081 ]
077c366c-911f-4086-ba19-8dd1a2316a7a: [91336 , 84298 , 35003 , 26217 , 92550 ]
4047f3f1-e491-4c36-a252-45cd8ef5dd91: [38603 , 32250 , 20649 , 40702 , 25677 ]
7a3b32bb-0b9b-42e3-8225-a1af3681db6e: [16985 , 75024 , 82590 , 90199 , 91473 ]
8e434bb9-f577-4519-a97a-73618c8e3b5b: [81174 , 22315 , 56194 , 21818 , 13937 ]
135287c8-0607-47d9-831c-86b886b95713: [85775 , 83315 , 83063 , 62446 , 17557 ]
1a58200d-6484-468e-9085-cd52900b5097: [81889 , 16847 , 54762 , 85049 , 12848 ]
193b92f0-3e9d-464a-b1b9-eb8ed3de26a1: [25448 , 58688 , 25474 , 41572 , 53098 ]
64f2470a-4fbf-4d89-aa13-fe269a420576: [97783 , 17898 , 50159 , 57126 , 19605 ]
cf71ffa6-c298-4df2-ab2d-9b2b3c208cd8: [50091 , 86107 , 29663 , 77819 , 82123 ]
29cec8d1-3ef1-4f35-8cca-429b3b56eef7: [62164 , 72235 , 62850 , 24843 , 64372 ]
da13eced-d846-4d59-9491-9c110c19a3a0: [35788 , 25235 , 79256 , 19720 , 45629 ]
7e9bb330-59c2-42e5-803a-a6b9d70f9be4: [30089 , 95666 , 90525 , 89551 , 58832 ]
02fec82f-310f-4bf2-8fc8-cee1c4c24fcc: [84201 , 43829 , 11101 , 16786 , 71972 ]
890f44d9-b04c-49aa-a876-673b71b0fcb0: [93587 , 14074 , 63743 , 60036 , 78900 ]
f77fbe77-5c64-4ada-a701-aca1057c400e: [24806 , 50228 , 14725 , 73603 , 80705 ]
3f6af0ed-eec8-473a-8a33-1beaad2c4149: [54532 , 86755 , 33705 , 95501 , 25489 ]
329593aa-be6c-4896-93c6-bbec08f0fb49: [57072 , 49197 , 27087 , 10046 , 46262 ]
ff4863d7-1a06-4565-b287-5d42c02d2ac7: [38551 , 71375 , 56814 , 23258 , 43905 ]
11c65c4f-fc43-4970-afd0-6849b7346898: [77063 , 83801 , 71308 , 24475 , 96467 ]
c279ff22-4d54-43c8-98cc-655630c4a37e: [83833 , 84260 , 37108 , 71258 , 59234 ]
b25facc1-77ac-432f-8338-86b00bae02e1: [83806 , 80755 , 51544 , 82368 , 35238 ]
43c2b37c-5f38-40f7-810e-4b5d093ee89d: [50200 , 50623 , 38546 , 39704 , 71108 ]
ea4667f6-3d7d-4e70-b582-863640d4511e: [19835 , 99311 , 20472 , 73414 , 90702 ]
9e550dda-4548-4c1b-9f09-49c715bbbc74: [21039 , 55686 , 56430 , 11765 , 35733 ]
f133dc75-46c3-4bce-a5b2-25b111e0aba9: [58086 , 82862 , 86997 , 16616 , 18968 ]
769e4a53-6d7c-4b71-a9c3-a79a01144537: [37520 , 70464 , 47919 , 33271 , 68299 ]
a9802b41-264a-4ecf-af68-cd9c4a08c775: [30616 , 75585 , 98068 , 71438 , 98541 ]
00b76ff2-d0b9-418c-bee1-5ca45e01db5e: [40423 , 71426 , 44365 , 44736 , 13280 ]
cbc81b26-e708-4827-87ff-290c32ee37c7: [92735 , 98198 , 43243 , 19768 , 24143 ]
014f7254-b2ba-443a-af30-39ceb0d17aa5: [87570 , 90114 , 25773 , 63870 , 63799 ]
a180012e-05f5-409f-a15d-8ef86efa3b65: [28718 , 50957 , 75669 , 77110 , 30820 ]
5fa76e8a-2362-40a9-bcf4-0f2c80b73d14: [82629 , 53450 , 78674 , 83779 , 18565 ]
fc36ae70-9e21-4d55-a7bb-f4622a522fdf: [85174 , 48428 , 37825 , 11509 , 88385 ]
53be5cb8-2b4f-48ae-bb07-80f97c36551a: [14053 , 70964 , 66672 , 94229 , 67142 ]
89172b9b-c69a-4eaf-a0b7-19d574b914f3: [49603 , 44514 , 69751 , 85016 , 34767 ]
ddb10ebe-ceff-49d4-9da9-9f2e6a4c9a75: [78555 , 61422 , 83048 , 88201 , 12927 ]
f568326d-78c6-4b81-ae90-a484da879d2b: [87674 , 12274 , 86069 , 75763 , 69130 ]
985fd63c-907c-4a17-8b8f-3dd37451f070: [44068 , 27705 , 58394 , 54533 , 37441 ]
4a628af3-d31e-47c4-ba88-dcf87b8fe53c: [66299 , 27093 , 53675 , 83661 , 52837 ]
b7f37ac6-81b3-4845-aa5c-a0cc82f6705b: [16848 , 98681 , 93819 , 91796 , 74022 ]
1ddd5f5a-6937-4cee-b5cb-8fab1eb1ef38: [93623 , 90160 , 90567 , 70952 , 54414 ]
2672b578-f122-47ed-80fd-360354c360ba: [35997 , 71871 , 95116 , 46711 , 79088 ]
8ad2c308-bb77-486b-a58f-b2639e54c06b: [29856 , 21942 , 16625 , 27504 , 36954 ]
8bc8828e-05b2-4ddb-ad0d-eb008c64bcb9: [29531 , 92221 , 24825 , 27540 , 59415 ]
5ac433ce-4725-4690-b18a-65d92f264ed8: [84489 , 78471 , 41825 , 24586 , 52838 ]
afedb721-b8b3-403f-a138-e5b73c484730: [14995 , 56447 , 72456 , 70494 , 37299 ]
5b0963c7-b446-450a-9775-2baee197093a: [44281 , 86545 , 53843 , 10082 , 88182 ]
116bb258-09a0-4781-a5e2-7ae0621c1a2b: [99137 , 41936 , 28330 , 34653 , 65698 ]
32211dc0-eb39-446c-8fcb-69d7db683dd4: [11140 , 57693 , 43252 , 80749 , 34596 ]
2a029364-c6de-4d07-a8e6-83dcf9495454: [65329 , 16513 , 63945 , 39726 , 61071 ]
dabe8093-4793-4086-8f19-3589cab190a5: [43622 , 53693 , 26057 , 40959 , 24022 ]
db415535-db7a-4d03-aeda-70df8292fc7b: [28244 , 27360 , 76420 , 24203 , 66585 ]
eb1991b6-bf89-4f2c-b841-4776d7ce6a2c: [64642 , 84411 , 37158 , 67305 , 40408 ]
fb675380-229d-4523-af24-3338613de1bc: [49020 , 66024 , 67887 , 18377 , 23649 ]
1b0b18bc-40e1-40ae-901c-9fc162fbe25f: [29371 , 33894 , 40677 , 62129 , 47027 ]
f32e4e5b-91e9-45ce-b21e-2c940e3306e3: [16161 , 22018 , 32929 , 33255 , 75681 ]
41ea6c01-6b6f-4db7-bbc2-5f39e8d91b52: [60068 , 97490 , 51959 , 23192 , 89055 ]
646dff6c-7e4e-4a34-bbef-e7079cad85b5: [82058 , 17176 , 44563 , 30080 , 41947 ]
93464c5d-141f-4796-8996-110929ac5dad: [37764 , 40382 , 92440 , 95404 , 38010 ]
266a47e0-cee1-43c3-a0a1-92efb8c66411: [96428 , 43534 , 22557 , 33171 , 48860 ]
adad6a9c-8fed-42b5-9312-b162ac1d883f: [52546 , 50375 , 56700 , 82046 , 74111 ]
6811d6a9-1695-4d01-a1ed-e1d316be0234: [98396 , 72785 , 77116 , 62688 , 28376 ]
ade4fcb0-d286-4f9d-9606-b48e492f8298: [53399 , 84855 , 78510 , 11018 , 10167 ]
1347f8ca-661f-456b-997d-f96b1c51df68: [63408 , 77730 , 38348 , 14821 , 83706 ]
783ba60b-3766-4d24-a74b-e52c78478b3f: [41741 , 57861 , 38011 , 72181 , 67868 ]
09fd466c-6146-4860-9690-efb7fb247094: [91608 , 73206 , 52065 , 80507 , 50287 ]
8c5e9d58-c8bd-4488-8a93-97bc2bd3b6a6: [30135 , 81004 , 53422 , 73587 , 62140 ]
c620de7a-9cfb-4eba-8552-03fa2bee954f: [23345 , 39530 , 86060 , 92255 , 78633 ]
9d789811-e83e-4437-8662-161f22c549e6: [43005 , 73385 , 46243 , 59172 , 97758 ]
275bdb8e-d0e2-4cc7-a709-87e820e49b23: [49825 , 61903 , 11727 , 59701 , 75268 ]
2164fe0d-d0a0-4851-a4b2-d162b180031a: [62851 , 38404 , 11876 , 32055 , 11233 ]
dedc4809-38dd-4e73-b5d6-fa30a7a21171: [90876 , 34534 , 27433 , 18470 , 11175 ]
27d37697-39ee-477d-ba07-6b0155879b3d: [23088 , 63703 , 36653 , 72629 , 14242 ]
af860c26-3b8d-4ec8-b7ae-16ca5e9014a4: [90280 , 73864 , 24448 , 58571 , 50341 ]
baf667e9-edc5-48ea-8e4f-c3061f6b78ff: [46933 , 46855 , 14438 , 71875 , 57250 ]
eda7c5d3-f3a4-405c-a124-c8531d695949: [90855 , 68673 , 74561 , 17614 , 14232 ]
1f54d07d-c7a7-4931-94be-5498932b200f: [76340 , 49421 , 72353 , 59867 , 49286 ]
7b9c52d4-1f80-4e36-b653-3fe266f61b43: [28221 , 12618 , 94419 , 41330 , 74511 ]
05bff2e3-fda6-4917-be54-33e1cd36c3c1: [15208 , 95224 , 60741 , 50724 , 70925 ]
5cbe99d7-0dda-4789-86ae-98fa066867ae: [43857 , 78976 , 29455 , 63334 , 54312 ]
45e978cb-e71e-4338-884a-79cb9c203283: [96267 , 34391 , 80523 , 69104 , 67756 ]
708e2a1d-e70a-4513-907b-8e64a7e18abe: [83522 , 34707 , 48334 , 19958 , 23264 ]
a7a05e60-26c8-48bc-9bb9-474a804ebf30: [46075 , 18950 , 22413 , 60004 , 82870 ]
60b298de-aa0c-46b8-ba58-cf939a99ae54: [71728 , 18624 , 77808 , 89169 , 26868 ]
c5be635a-8570-41b2-8abb-b646e4fe501c: [27879 , 37215 , 99305 , 11303 , 49469 ]
03e1fa4d-f5fa-46f8-8453-213a14ff83cc: [89613 , 84954 , 16269 , 74458 , 30669 ]
9deb5e4e-7c45-4a73-9c06-654e86f3eab3: [47636 , 51201 , 66425 , 38277 , 58601 ]
dd4ec61e-f619-49bd-add9-3e5397e2b39c: [76131 , 27930 , 54921 , 79976 , 22152 ]
d5a0bb43-d9f7-4eaa-b4c0-aa034adb5d6f: [82609 , 34006 , 37479 , 65608 , 42589 ]
8853d73b-33fd-4a88-87a0-a3827d30092e: [86046 , 93042 , 10414 , 46896 , 11714 ]
b8eadb53-5aad-48f8-b4e2-e56a568b2be3: [39452 , 74172 , 92908 , 76907 , 30320 ]
7f71c7c8-75ff-4a90-93c2-e5a52f93f78a: [68795 , 70419 , 94900 , 17189 , 82233 ]
c94e4039-78ad-41af-887a-0c2cc69e37be: [42904 , 31423 , 72536 , 56521 , 10055 ]
4606270f-e967-4f21-b256-f1c7a6bc48b4: [23921 , 56241 , 31990 , 52247 , 66452 ]
a2aa8d16-6eb3-433f-99fb-eeb76f4ea453: [12634 , 10932 , 41279 , 84220 , 63084 ]
67c2d664-1d40-4a41-ac10-df9e87110a1f: [39591 , 49413 , 49658 , 82915 , 55508 ]
829d8efe-ddde-4414-981c-5669bacd5396: [31338 , 87583 , 27923 , 55585 , 57757 ]
16eb63d8-ca24-472b-9393-fc444194a836: [69314 , 37808 , 87836 , 52830 , 79038 ]
ca96caa4-1ed5-455f-9fcb-4b3ec427988d: [13082 , 88294 , 41184 , 70312 , 15133 ]
24f4e7be-8943-4a97-a213-637eb3634e7d: [53313 , 21868 , 12722 , 23875 , 58633 ]
36379606-76e9-4ffd-aec3-9863d9ce0bb6: [63103 , 33669 , 24602 , 30305 , 27084 ]
f6eb787b-1b59-429a-8f6e-81dd544982e5: [43812 , 37175 , 82848 , 16976 , 82787 ]
3af15328-326d-47bf-8820-fb731ff55b2a: [92969 , 52591 , 71115 , 49750 , 37211 ]
8811b1f9-ca73-44b3-9caf-669ea71bc12e: [74497 , 13693 , 63856 , 72416 , 85856 ]
455ea770-880e-4b6e-86f2-19e09c6aec4f: [78163 , 30434 , 72528 , 81902 , 88896 ]
5a8cd3a6-4307-448e-a53f-354ee0331f81: [13877 , 58574 , 48496 , 19840 , 17424 ]
178fbee1-9bde-418f-ada7-d90871c99d2c: [79517 , 50585 , 69984 , 62416 , 40814 ]
3f84afbf-af34-4ae8-9318-4e90d7031297: [13077 , 25550 , 81347 , 38482 , 83635 ]
9deefe11-561c-4012-9cea-a870522bfced: [89856 , 60870 , 65476 , 12353 , 89229 ]
543d4bb2-4854-4294-b8f7-396e9da04a25: [21673 , 23961 , 65217 , 87611 , 21872 ]
eae8706f-2c9c-447f-966e-e4388ceb5ac6: [33241 , 52821 , 26114 , 35832 , 47942 ]
9d529b0f-e878-4f4c-9088-6ab0badf7731: [18670 , 37474 , 39996 , 12991 , 35873 ]
1311767d-1705-4702-9881-0b7594312aef: [45561 , 85363 , 62491 , 56844 , 95547 ]
418b392e-6d29-4dce-98c6-e1411877c0b5: [46020 , 81285 , 49332 , 59932 , 32916 ]
d18a419a-6774-4469-99fe-0a34daf24f8b: [26132 , 23827 , 67385 , 70798 , 20098 ]
e644dc6e-d9e8-44cb-a567-94b752c8ead6: [83090 , 18062 , 18829 , 48230 , 88584 ]
9345a5d6-70dc-44a6-8463-56dc1bc72bb7: [48732 , 79760 , 61948 , 44090 , 38493 ]
d751eff7-1cb3-407d-b13d-c245dbb7ecb4: [94334 , 10441 , 27617 , 60426 , 84923 ]
c8c2e1cf-4f50-4e2f-9cb7-79c3b6b776ae: [51704 , 72914 , 91469 , 63382 , 30479 ]
b7c476fe-6d31-45ab-89be-007ee3275c33: [19134 , 15744 , 69408 , 52464 , 89642 ]
225ad246-3aa5-4e8e-87a3-8e79de120b2c: [26814 , 42436 , 86192 , 69858 , 19740 ]
147cd76b-280a-42a3-8d91-d9d67e1376e1: [87849 , 92385 , 95664 , 27237 , 13661 ]
85083788-60b7-4a3d-8494-c76b5f7967d2: [98247 , 68417 , 88474 , 92391 , 70014 ]
24bd80cd-729c-478b-8192-cc71080b5f47: [34928 , 62726 , 30673 , 65563 , 90634 ]
4109791f-e6db-412b-93dd-b6f87139db21: [74129 , 38782 , 54712 , 93013 , 26584 ]
8398fd30-cf91-45dc-8ba1-bda01f01f093: [98294 , 26957 , 23676 , 81137 , 57070 ]
bfc09c0b-8dd1-4679-9eb4-36a1a34915bb: [53195 , 16567 , 22652 , 99001 , 66157 ]
d57a1e96-90bd-40d1-8b5a-56c5fe123af6: [55535 , 54148 , 21551 , 36333 , 24573 ]


how_decide
I am not sure exactly how it works. I think it looks for several keywords associated with one of the two sports, but not the other, but I don't think I was ever told exactly how it works.	85192 
key words like pitch, throw, goal, NHL, MLB, ball, puck, Leafs, etc. It could sort those into the appropriate side.	91336 
i'm not for sure	83806 
it was probably programmed with key words that helped it make its decision.  for example, some team names were probably named as hockey teams, while others were named as baseball teams.  also, some key terms such as strike outs, home runs, world series, goals, playoffs, etc were named.  what probably gave the model problems was when a term is used in both sports.  "playoffs" and "champions" are examples.	73280 
using team names or specific terminology 	67214 
It used keywords.	97854 
It uses keywords mentioned in the articles.	46075 
I think it tried it's bet, but would often highlight pointless words that didn't indicate anything of value. 	81889 
I think it just looked for keywords and used that to 	90280 
It tried to pick out key words in each email that were directly associated with either baseball or hockey.	35788 
i think it had a preset list of names of the teams to help it decide, but i am not completely confident about that.	39788 
The model used certain words to determine whether emails were about hockey or hockey. Sometimes the words weren't relevant, but they mostly were.	69314 
The machine used key words found in the emails and determined from there.	30025 
I think the model uses keywords to discern if the email is about baseball or hockey.	37805 
I think it looks for words that are associated with the particular sport. 	29856 
It looked for team names, keywords like "hit" and of course words like NHL, MLB, baseball or hockey	74129 
From specific tag words about either sport.	48732 
I think that it looked for certain keywords.	77063 
It took certain keywords on the screen and made a smart choice about what sport it was talking about.	63103 
It decided based on the presence of certain keywords.	63408 
Based on keywords such as team name, player's name	63547 
I think it looked for keywords related to either sport	93623 
There were some pretty good keywords to help the machine learning model decide if they were about baseball or hockey. The model took those words into account.	25448 
Picked out key words and decided if it was about baseball or hockey	89937 
I think it looked for certain keywords that are more likely to be associated with that particular sport, e.g. stick for hockey, or innings for baseball, etc. 	86046 
I think it used a database of words that matched common sports terms and team names to each sport. 	77328 
I believe it may have learned to change the choice based on feedback on errors from Part 2.  It may adjust if it knew that the original choice was wrong or perhaps it will use different terms to make its choice.	30089 
It searches for keywords that can be assigned to a specific sport and team names.	48664 
The ML picked out certain keywords, sometimes relevant like team names or jargon, other times random words with no connection so not sure how it was using those to decide.	45561 
it looked at names and whether language contained anything related to baseball or hockey.	46933 
The machine used a few keywords to decide what the email was about.  In my opinion, it wasn't always the right words or the most obvious words but many times the machine got it right so I supposed based on their algorithm they were, in fact, the right words. 	64642 
Mostly by the people mentions or the instruments used in the game.	14995 
It decided based on the words highlighted in yellow that it decided as important for describing each particular email.	32228 
It looked for keywords like no hitter, ice, MLB, NHL, and team names. It was able to decide which sport these belonged to. 	87570 
I think it looked for key words, like team names, player names, and words like NHL or MLB, "pitcher," "hitter," "goalie," etc.	13877 
I think it looked for certain words that it could try and relate to the sport	33251 
The model did an excellent job of correctly figuring out emails detailing the basic talking points of each sport and being exact in its guess. The model had issues with emails that were used vague language, and limited wording about the sport and people's names.	60065 
The ML model differentiated between the two sports topics using the presence of certain high frequency terms/words that are commonly associated with one sport, but not with the other i.e. pitches, ball, Cup, run, etc. 	40423 
Mentioning of skating or ice generally means the email is about hockey. Fielding or homeruns will mean baseball. Just analyzing the words used in the email will tell the model whether the email is about baseball or hockey.	78555 
The machine learning model looked for keywords that it had determined were either about hockey or baseball I believe. 	95868 
The machine learning uses certain key-words to help decide whether its hockey or baseball.	76131 
It will look at the terms and teams.	78163 
probably had a list of keywords to look for to classify emails	23921 
Honestly i'm not sure. I'm pretty sure it got one wrong that should have been baseball and the team dodger was in it. SO maybe it isn't by team name. A 	76340 
I think it looked for keywords of teams/the sports term itself.. IIRC the only one it missed had no real terms in it outside "DL" which is a baseball term abbreviation but not super specific.	85174 
It looked for words that it thought was an indicator of the answer. Like a sports team or city.	62851 
It picked words it deemed were related to baseball or related to hockey in order to make this choice.It didn't seem to have much specific knowledge of either sport though, and a lot of the words it used seemed mostly random. I'm not sure how it reasoned that ordinary words or that a name like Frank would distinguish hockey from baseball. Some of them it seemed to get right by guessing. 	60068 
Whether certain words were in the email (NHL, AL, team names, terms used only in that sport).	13082 
I don't know	97783 
i think it made judgments based on some key terms and scoring layout or numbers commonly used between baseball and hockey.	28244 
it looks for proper nouns and terms that are specific to hockey or baseball, but it also highlights some words that don't have any special meaning, like words like "well"	39300 
It used certain keywords that were supposed to indicate hockey, or baseball, but some of the keywords were meaningless, so it was inaccurate at times. How it got these keywords, I have no idea. Probably some statistical analysis of other articles, which produced slightly flawed results.	93181 
It looks for key words to help determine the subject of the email.	53313 
It seemed to look for certain keywords like team names, but also seemed to highlight what seemed like a lot of random words	27879 
It seemed to use certain keywords, either something involved in the game itself (hitting, batting, etc.) or in some cases just knew what the teams were associated with (Islanders-hockey, Sox-baseball, etc)	52546 
it took team names, cities and events in the text and isolated which sport was being talked about from these features. so a specific term like stanley cup would signal the the ML that it was a hockey event.	71990 
I think it must have recognize some words exclusive to/mostly used only in the context of sports, or the names of sports teams/leagues themselves. So that might be something like knowing the Phils and homeruns are baseball, or the Caps and goals are hockey. But it's hard to tell when it got most of them correct the first time around (I think).	82058 
I tried to base it on the words that were highlighted previously.	80302 
They pick out key words	82609 
It looks for common terms for each sport, and then decides based on how frequent those words appear in the emails.	13884 
It chose based on keywords contained in the email.	21673 
I think it was programmed with key words to look for.  I don't think the key words that it was programmed to look for were always very good though and I have no idea how or who chose those key words.  There was probably an algorithm of some sort that weighed the keywords and would decide if there was more weight to hockey or baseball.	39452 
I think the models looks for key words, or initials, pertaining to the respective sport.	43812 
I believe the machine looked for distinctive words to either sport.  Ball, home run, strikeout etc for baseball.  Shot, goal and stick for hockey. 	90718 
If the model correctly identified keywords in the email	51704 
I think the model used the names of the teams or players to decide.	97414 
Sometimes it used terms that would normally be used in each sport. Sometimes, it didn't use any word that made sense and it felt like it was a random guess.	98247 
There were certain words that the model would attribute to one or the other sport.	43613 
It reads and looks for team names, player names, as well as key sport terms. Hockey and baseball are distinct in this regard.	68795 
It looks at specific words and made a decision based on those.	26132 
It took certain keywords that usually only apply in hockey(ice) vs baseball(ball) to make its decision	31338 
in the trials it only made 2 mistakes that im aware of and i didnt notice anything that led me to understand why it was wrong on those 2 if i had to guess i would say if there are less keywords the accuracy goes down	91801 
The machine learning model likely used a series of keywords in order to decide whether the emails were about baseball or hockey.  Most likely there were first-order terms, such as the words "baseball" or "hockey", that the machine learning model used to decide.  Then there would be second order terms, such as "pitcher" "catcher" "inning" or "puck" "rink" "ice".  These were then followed by team names or team cities, then player names. I believe that confusion would occur if this information were missing or there was overlap in a player's last name between a baseball player's and a hockey player's.  However, the model would use my subsequent feedback to correct and refine its predictions.	74497 
it pulled common words used for that sport and made the decision based on that	71180 
looked for team names and events unique to each sport. Could be confused by seeing "hat" and 'cap" together, however.	54532 
I think it searched for keywords in the email that had to do with either baseball or hockey. One example would be one that said Todd Worell wasn't throwing the ball. This would have to be baseball since they use a puck in hockey, not a ball. It also probably searched for team names and matched them with a list of baseball teams and hockey teams. This would work for the most part, although both baseball and hockey have teams named Rangers, Texas Rangers in baseball and NY Rangers in hockey.	71728 
It picked up keywords that would only apply to baseball or hockey or it would determine it from Team names.	49603 
I am not sure.	43857 
It seemed to categorize emails as hockey if they contained phrases like Stanley Cup or Leafs, and baseball if the emails had terms like no-hitter or the names of baseball teams	53399 
I guess it just looked for team names and sport specific lingo. Not sure how else it would know.	93587 
It was looking for specific keywords relevant to each particular sport. Things like team names, terms and player names.	43568 
I think it took what it saw, like names or teams and tried to decide from there, I don't think it looked up what teams or names belonged to which sport, I think it took what subjects were in the topic, if it said baseball trivia or something to do with hockey, it made it's guess on that, and not the names of players or teams. It made mistakes as most teams were about baseball but it guessed hockey. 	92969 
I think the machine looked for key words associated with each sport. I couldn't really tell if it was looking at team or player names in its decisions, but I think it was specific terms used in each sport, as well as league names.	45133 
It inferred based on the language and abbreviations used.	14053 
it looked at keywords in the emails and associated them to the topics?	18670 
They tried to pick out the key words to which sport they are talking about.	92735 
It decided by picking out key words that were related to the sport or used to describe it.	16985 
It seems to key in on certain words or names  that are associated with the sport and classifies accordingly.	85775 
if the word ball or inning etc was in the email, baseball would be assumed. If NHL, stanley cup or goal was mentioned, it would choose hockey	28718 
lOOKED FOR THE MENTION OF EITHER APORT THEN LOOKED FOR TEAMS AOCIATED WITH SPORT THEN PLAYERS THEN INFO STADIUMS FINALLY IT GUESSED 	92831 
I think it searched for words that were most associated with either game 	84732 
I think it focused on specific words or team names that belonged to either sport.	38603 
It looked for certain key words unique to each sport, such as 'goal' or 'pitch'.  It did have difficulty with words common to both like 'Caps' and 'game'.	34909 
I think by using certain key words that are related to the sports. If none, then it went with Hockey.	72760 
It seemed to just pick random words out of the emails and try to make a judgement from those. There didn't seem to be much else to it. They missed a bunch of words that would have much more effectively identified what sport.	83833 
I think it used an algorithm to scan for keywords, phrases or names relating to either baseball or hockey. 	53195 
by some key words in the text	37520 
I have no idea. It picked completely insane words like "for" "like" as reasons it chose one over the other. I'm not convinced it wasn't just randomly picking and got lucky.	15208 
I don't think I figured it out. I did notice that some locations like "Boston" and "LA" were highlighted as well as words like "hit" etc but IS still feel like in some emails just random non-sports related words were highlighted. 	21039 
It detected certain words that are associated with each sports (team names, home runs, goals, puck, bullpen) and used them to determine which sport was most likely being talked about.	83522 
It looked for keywords, especially for names of teams or names of events, like the Stanley Cup playoffs or the world championship of baseball	46910 
Certain keywords that were tagged before, I believe the model will associate those words with either baseball or hockey. It will then decide based on that which are hockey emails or baseball emails.	16848 
At first it seemed that the words the model was using weren't relevant to whether the sport was baseball or hockey at all. It seemed like it was just focusing on random words, however as the emails went on it started focusing on words that gave clues to which sport it was, for instance a team name or a trophy name or an action that happens in only that sport "hitter" "goal". I think once it learned the relevant words for each sport it looked for those words in the emails and made its decision based on their presence.	34928 
It used keywords related to either baseball or hockey to determine the subject of the emails.	66299 
It found words that were closely related to each sport	63223 
It searched for keywords and determined what words were associated with each sport.	30135 
I felt like the model determined whether the emails were about baseball or hockey based on keywords and names mentioned. For example, if the name of a hockey team or hockey player was mentioned, it might determine it was about Hockey - and likewise for baseball. I felt like some obvious keywords like "baseball" or "hockey" were used, but less obvious ones like "goal" wasn't used, which caused the Machine Learning Model to make the wrong decisions about a small handful of emails when there wasn't anything more obvious in the email.	94334 
It used keywords associated with each sport to determine which one it belonged to	90855 
It took key words and decided if the email was about baseball or hockey.	37764 
I really don't know. It seemed to me like the algorithm ignored many of the most important words and instead focused on ambiguous words like "Frank" for some inexplicable reason. So I have no idea.	74192 
The machine looked for specific words that talked about one of the teams. I found that the emails had specific words pertaining to one of the teams.	42636 
The machine learning model took words already supplied and feedback from me to determine whether emails were about baseball or hockey. 	29531 
I think it uses keywords. 	79517 
It looked at team names quite a bit. It also looked at locations and was likely to attribute Canadian locations to hockey. 	12634 
It picked up key words that came into the view.	17209 
It looked for key words of teams and for words that are specific to the game.	24806 
It used certain words to see if it was more likely to be baseball or hockey	13077 
i think it prob scanned for keywords like: homerun, stanley cup, etc and made a determination that way	38551 
It found words within the email that had to do with either of the sports. 	17463 
Some were based on teams names, but many highlighted words had nothing to do with making an accurate choice.	33241 
Based on key words that I've seen it use before, like name of major leagues, players, big teams, things like "pitch" for baseball or "goal" for hockey helps the machine make their decision.	89329 
If the machine recognized anything word related to baseball or hockey it selected the appropriate sport. If the email was on that included both sports it went with hockey. The word could be a sport term, league, or player.	84489 
it took a few key words, like pitch, or hit, or goal, stick, and made the decision if it was hockey or baseball for the most part it was correct, some emails, however, didn't have specific key words, and were a bit more difficult, so it had to guess.	87674 
They went by the high lighted words,which were like hints to it.	23088 
I think it took words that belong to each sport "stick" "puck" "hockey" vs "ball" "hit run" baseball" and analyzed them that way	62164 
For the most part, the machine learning model identified keywords in each email which led it to conclude whether it was about baseball or hockey. In some scenarios, the chosen words were largely inconsequential which may have potentially impacted the model's decision making in a negative way. But in other cases, the model did a good job of singling out relevant keywords -- like terminology unique to a single sport, or a city or team name -- to help it make accurate decisions.	87849 
I think the machine decided by picking out player's names or the names of the teams. Also, I noticed that it may have picked out a random name or phrase relating to the sport-such as the Stanley Cup.	90636 
The machine used team names and sport terms to decide the sport. 	35997 
Certain keywords.	42904 
It took certain words like red sox to decide baseball and other words like NHL to pick hockey	58086 
I'm not sure. It seemed to be more accurate when there were team names though.	89856 
I think it was able to tell by the e-mail mentioning something specific about hockey or baseball. But when it wasn't obvious, the machine had trouble and would then choose the wrong sport. 	45237 
I think that it searched for keywords that are associated with either sport and determined it that way.	65329 
By looking for certain words and combinations of words that it has learned over time refer to which sport	49825 
The machine learning model evaluate words within the emails to determine if they are more baseball or hockey related in order to decide whether or not each email is more likely to belong to the topic of baseball or hockey. In other words, the model read the email in order to find key words which it then uses to generate a probability of the email belonging to one category over the other. 	19835 
I noticed that there were several of the correct options had words that were highlighted that were team names and cities to indicate which sport it was.   	90876 
based on key words	37817 
keywords like Leafs, Red Sox, etc	23386 
The model picked out team names.  The model picked out actions that are unique to baseball or hockey	55535 
It looked for certain keywords in relation to either hockey or baseball.	49020 
Finding key words. Learning from feedback.	43005 
I think it heavily depended on team names (e.g. Leafs, Red Sox) and the presence of the words 'baseball' and 'hockey' or those very closely associated with it.	41741 
It likely looks for key words that it associates with those sports.	30616 
Key terms in the email	91608 
I believe it relied on the actual words that were obvious to a particular sport.	30236 
It looked for key words or phrases that related to the sport such as team names or types of action.	46020 
It appeared that it was using keywords to decide as humans do what the subject is about. It didn't use the keywords I would have thought, but it was able to use words that were exclusive to each sport.	26814 
It searched for keywords that are typically associated with one sport or the other.  For example "ice" would be hockey, and "homerun" is obviously baseball.  The more new words it picks up, the better it will predict the sport. 	38418 
The machine looked for words such as "pitcher", "Stanley Cup", and team names to decide which sport was being discussed.	83200 
The machine looked at terms that are relevant to hockey or baseball and decided based on if the email had a lot of these phrases.	96267 
used key words in the message and subject line	81174 
It looks for keywords that can easily be attributed to a baseball or hockey conversation and bases its' decision off of those words.	39591 
I think it tried to recognize names and phrases that were distinct to each sport.	50091 
Certain words	47636 
It picked out certain words that are associated with either baseball or hockey.  It used a majority of those picked words to make a decision.	44068 
By finding key terms relative to the specific sport(runs, pitch, goal, save, pitcher, ice)	19134 
It looked for keywords that are associated with hockey vs baseball	82629 
it looks for references to entities like teams and leagues.	17595 
I think the machine learning model decided was because of the team names. Some were either baseball team names or hockey team names. Also, I think some words are used in baseball and some in hockey, and it decided by those words.	11140 
\nI pay attention to sports. I miss the Thrashers and will argue about about "Atlanta Dream" will be a nightmare in my life.  	83090 
It picked out specific key words related to the sport and made decisions using these keywords to categorize the emails.	38703 
It seemed like they may have took keywords and matched them to a database to come up if they were about baseball or hockey. Keywords such as a player's name or a team, possibly even a city.	99137 
it seemed to be looking for keywords	16161 
I think the machine was very smart and knew what words to look for.  It was right more often than not.  I only remember one wrong one.	84201 
it focused on certain game-related words, such as "pitch," but it also (more helpfully) focused on SPORT-related terms, like "NHL" or "Stanley Cup." I couldn't decide if it knew the relevant player names (like Worrell), which is a weakness, and there were problems with the emails themselves, like the misspelling of "Angels" which made it harder for the ML to be successful. 	68374 
It seemed to look for team names.	23345 
It decides based on key words present in the emails.	43622 
it picked at times random words that it thought fit into a model of the game	50200 
The model took keywords from the emails to make an accurate decision. The model looked for actions words related to the sports or team names and players.	96428 
The model focused on a set of words for each category (baseball and hockey) that I assume were weighted to a certain extent, and if more of those words were present, the model decided that the email was about that category.	89613 
It noticed key words in the text	57072 
It used the words in the email to look at what the text was about, and made an educated guess based on the words.	28221 
It looked for keywords that were associated with either hockey or baseball. 	98294 
I think it looked at the teams names that could be baseball or hockey and sorted that easy. I think sometimes it took keywords related to either sport and interpreted that. It checked for reconized player names. Sometimes i don't know why it used random words that wasn't related at all.	98396 
I think it looked for words like "goal", "pitch" "FHL",etc to help sort them out.	29371 
Team names, certain key words, and player names I think were used.	44281 
printed 176


overall
I felt good about it. I mostly trust the model. It did a pretty good job.	61422 
I felt like it was accurate and easy to train	12618 
It seemed easy to use and understand	84855 
I felt really good about the experience. 	37808 
It needs a lot of work.	23961 
Positive. Fixing which words it looked at, as well as taking more than 3 keywords into account, would help a lot. 	10932 
I like the idea of the model. It was successful the majority of the time.	53266 
It was pretty interesting	38782 
Very good experience. I was surprise how well the model performed.	25483 
I had a positive experience, there were no glitches and it works well	45589 
I found it frustrating even though the model was successful.	74407 
I felt it was a good experience - it seemed like it would speed up the classification of emails quite a bit. With that said however, it may need some refinement if the emails in question were of a critical nature - or at least a human to quickly scan the email contents to make sure it was correct.	10441 
This model is great but could use just a little work.	27930 
It was a fun experience. It was fun getting use to the machine.	31423 
Overall my experience was fairly positive.	34707 
I was fairly impressed by what seemed to be an accurate model.	26957 
It was pretty straight forward using it and it worked well.	83315 
It was a neutral experience overall.  It was okay.	27705 
I think it is fun to work with and works very well.	37175 
I enjoyed it, thanks for the opportunity.	81285 
I found the model to be accurate and I enjoyed seeing how it made it's classifications.	15744 
I felt it was fine	82918 
I was comfortable using the machine and it was kinda fun interacting with it to figure out how it made it's choices. 	34534 
It was fine.	38404 
I felt like the experience was pretty good and helpful.	53668 
i was surprised that it was mainly accurate in the practice so i developed a level of trust with the model 	35467 
It was a vaguely positive experience.	87583 
I enjoyed it and found it useful.	21868 
I like it	86435 
Good, I thought it did well.	42208 
I liked it I think that it would save people time in certain circumstances.	86107 
Ok, I would take the time to make it learn.	62071 
It was fun! The AI was mostly right and I could understand why it was wrong when it was.	68673 
It was fun	72914 
it was very smart	73595 
It was fun, though I did not really know how it worked.	60870 
It did a good job.	63703 
i thought it was fine and can see it's application in certain instances	71375 
I enjoyed it very much. 	84411 
it helps but not perfect	22315 
I enjoyed the experience and feel comfortable with the program.	58574 
Good overall.  At least it wasn't an exercise in frustration as with some other models.	50375 
it was fun	48113 
It went well. It wasn't perfect, but the results were better than expected.	83801 
i think it still needs improvement but it has potential and decent accuracy in sorting between to different topics	27360 
I didn't mind it and I find machine learning and model stuff like this interesting in general, so it was interesting if nothing else. I would've liked to see how quickly it could wind up learning.	17176 
I felt like it was easy to use and helpful in making decisions.	57693 
I think it was a learning experience for both of us.	18950 
it was interesting	20260 
I was impressed at how well the model worked and would have fun training it to fit my purposes.	84298 
seemed to work well and if it can be taught mistakes will work better	87020 
The experience was good. The model appeared to be in working order.	66024 
i liked it. i wish I could do more like this	80755 
I liked it overall. I thought it was neat how it could pick the correct choice between some of the harder ones. Granted many of them were easy, but it did pick correctly on some that weren't.	41936 
I feel like it can eventually become more adept then a human.	44514 
Using the model has been a good experience primarily due to how reliable it has been.	99311 
It was painless and pretty easy all things considered.	95224 
it was ok, a little fun really.	55201 
It was fascinating. I miss hockey in my city. And baseball. I think this it's interesting. 	18062 
I was skeptical it was an actual AI, I feel it was just stuff arbitrarily selected by the experimenter.	29311 
I felt that it was easy to understand how the model made its determinations. I felt the system was easy to navigate. 	92221 
I found the task of using the model interesting.	27093 
It needs some more datapoints, but I can see it being very good	53450 
i enjoyed it.  it brought back memories from times i was much younger.  there is no doubt that a younger fan would not be able to do as well as i did in identifying the sport.  i got them all right (except one which i had to guess at because it gave me no clues at all).  i think if the model is improved it can be superb but as of now it's not reliable.	39304 
This took too long. Some of the emails I couldn't tell and at least one email I'm sure mentioned both sports.	75585 
I think this model proved to be useful. I would feel confident using it again. 	71871 
It was a positive experience.	34160 
It was fine? 	48428 
It was a good attempt that's headed in the right direction. However the keyword data set needs to be overhauled to include jargon specific to the sports and generic terms need to be eliminated to improve overall accuracy.	85363 
I think it worked well.	86545 
I really enjoyed it	54148 
It was cool Thank you.	70464 
I love it and would use it.	36508 
I enjoyed it.	44731 
I liked it.	49197 
Good and like it.	98198 
It was really simple and easy to use.	39267 
I feel really good about it and i would use it in my own business. 	33669 
i felt like it had some knowledge about how to make decisions on e-mails but it is far too inaccurate	33396 
mixed feelings	17898 
It was a pleasant experience	16513 
It was okay. I think the machine had a pretty good grasp of what it was looking for, or at least it seemed that way.	52936 
It was easy to use, but I did not get enough feedback. I did not know if I was feeding the system the correct words or if it was learning as it should.	90130 
I thought it was interesting and it did remarkably well, better than I thought it would.	84509 
I found it fairly easy to use for someone who doesn't know much about the sports mentioned.	56447 
I felt generally positive about it, if a little uncertain. I thought it did a decent job of categorizing the emails, even if the words it chose didn't always match what I'd consider good indicators of which sport the emails were talking about.	84954 
I thought it was adequate for this task but I wouldn't trust it for company-wide use for something important.	43087 
I thought it did a really good job	73864 
I thought it was predictable and accurate.	77730 
I liked it.	78976 
I didn't really think it was the best or most accurate model	37215 
It was interesting, but the model needs more work and time.	16847 
It was easy to use. No real issue.	14074 
It was easy to use	52821 
I liked having to guess which the model would guess.	81004 
I liked the model, but it needs some work. The highlighted words weren't that great compared to really obvious keywords like team names.	42436 
I loved the experience of using the model. It was very interesting to learn about a new model that will help lots of people.	56717 
I felt the model was very lacking in quality in the sense that there were obvious keywords that should have been considered but weren't, which made me frustrated at the programming.	59284 
positive expetience, it made predictions for hard to guess emails	44933 
I felt it was fun, like programming a modeling software	77527 
It felt good because it helped me understand the subjects of the emails even if I was unfamiliar with the topic.	34391 
it was interesting to see how it thought what was what	50623 
I enjoyed it 	96710 
it worked well i think.	37474 
I thought the model was great for what it was trying to accomplish.	98681 
It was correct a decent amount of the time, but seemingly for the wrong reasons 	84260 
I feel that it still needs improvement for there were some errors made by the model.	53693 
It worked well	73206 
It was good.  It is a useful tool.	38032 
Needs to reach human level	31915 
It was more accurate than I expected, and I was pleasantly surprised.  	45503 
I trusted the model because it made consistent and accurate decisions, I felt as if we were working together.	13522 
I thought it was interesting and it was somewhat enjoyable.	62726 
I really liked it I would be curious how it learned as it went along	82862 
I think it was interesting and effective.	23827 
I felt good about the experience of using the model. I was able to learn something by using the model and I could help the model improve by helping to correct the mistakes.	43534 
It seemed to do any okay job. It needs it's vocab expanded. 	50585 
I felt positive and expected the machine to be correct.  I believe there was a soccer passage about Switzerland  	75987 
I honestly enjoyed using the model and was more impressed than I anticipated being by its relatively good accuracy. Moreover, I understood the instances where the ML model may have gotten confused and selected the wrong answer i.e. the Caps example referred to above. 	71426 
It was fun to use and I liked it.	78471 
It went well and was interesting to see artificial intelligence work.	39530 
I felt that the experience using this model was helpful and informative.	75024 
I liked it I think it worked well	22018 
I had fun using it.	25235 
I thought the model was pretty good and just needed to be trained a bit more.	79045 
It was sort of interesting to try to figure out how it made its determinations. But I also wondered why it had so little knowledge of each sport. It was frustrating at times seeing words in an email that would are unique to hockey or unique to baseball and not see the model uses those to make its decisions. I felt like it got lucky in some of its choices. 	97490 
My overall sense of the model is that it's pretty intuitive, though there is still work to be done before I would feel completely confident about its success rate over time. I would describe the experience of using this model as pleasant, entertaining, interesting, and made me feel curious about how it arrives at the conclusions it does.	92385 
It was fairly accurate, though some were hard to tell. Overall it was easy to use	25550 
So much confusions.	30434 
I like the idea, seems like a strong way to sort emails	72235 
I enjoyed seeing what the model thought, and thinking about what the model thought.	58688 
I enjoyed using the model, to see what its capabilities are and how well it would be able to categorize the e-mails on its own. 	68888 
Positive overall.  Easy to use.	70964 
Overall it was a positive experience, but it obviously needs more training, especially when it comes to figure out how how certain words are used in context. 	93042 
I thought the experience was well paced and straightforward.	37310 
It was interesting, trying to guess what the machine is doing 	66451 
it was good	11935 
Fine, I had no issues	10900 
I felt that this experience was good.  The model wasn't too far off of its ideal performance levels and would likely be able to refine its predictive capabilities with some minor feedback.	13693 
I thought it was easy to use and didn't have any trouble with it flagging false results. 	90114 
It was easy to use and generally correct.	61903 
It was pretty accurate and easy to use. 	16567 
It was pleasant because I didn't feel like I was correcting it or it wasn't working.	79444 
I feel like I should have gone into model development. This model is not very good and will lead to great frustration.	86755 
It was ok, but I feel like it was an exercise and not really working with ML	79760 
it was pretty easy to use and overall pretty accurate so i thought it was a great experience.	32250 
It was fun	51201 
It was more accurate than I thought it would be, but there were emails that could have been about either, and one that mentioned both baseball and hockey, so a third "not sure" or "both" option would make it more accurate.	18624 
It was an interesting experience. I would hope it would improve over time though.	68417 
I thought it was interesting and challenging and a nice break from the typical academic study.	74172 
I thought the machine was smart and did very well. It was fun checking and working with the model.	33894 
I liked using the model and it was a pleasant experience it seemed helpful at least to sort through emails.	72785 
I thought it was useful. I would wonder how it would handle adding more topics and if it was customizable to include industry-specific words that would make it more useful. 	25318 
The model performed reasonably well and hopefully I was helping it learn by selecting the correct answers. 	61361 
I thought the model was pretty effective and that I would be able to help it be even more effective with my input.	49413 
It was very good.	88294 
I feel neutral. It could be a useful tool but I wouldnt trust it completely	90160 
It was kind of fun and interactive	50957 
depends on if the model would adjust in the future. right now for the first 10 emails it didnt do a good job	56241 
Interesting and I like interacting in it.  I am not sure if I was able to influence it to start making correct choices when it had chosen incorrectly in earlier phase.  I did like the idea and ability to use technology to help sorting.	95666 
It was interesting and could end up being useful for some companies.	17347 
I enjoyed it and found it interesting that it did so well.	50228 
I had a lot of fun with this HIT.	43829 
It felt reliable and trustworthy. It only had trouble when not many of the common keywords were used.	72470 
It was decent	34006 
I think it was very easy and sorted the emails well.	21942 
I enjoyed it but kind of felt frustrated that i couldn't figure out how it was going about sorting.	49421 
I liked it.	13134 
It was fun trying to figure out how it was choosing the keywords it depended on.	57861 
It was fine, right some of time, wrong more of the time, but it's still got some right and with some more input it would be really good. 	52591 
I enjoyed trying to see if I could guess what the model would choose, it was a good experience for me. I wish I could have more time and examples to try to figure it out! 	55686 
It was fun experience but at the same time it was little difficult to know why its making a mistake when answer was obvious to human.	46855 
I felt it was interesting. I felt unsure about some of the emails.	73385 
I felt that it was a good experience. 	40382 
This was interesting, just not sure how it chose the highlighted words on a few of them, but for the most part chose correct words that could interpret which emails it was referring to.	12274 
It was easy to use and understand. The logic was easy to follow.	70419 
printed 176


frustration_why
It's usually right even though I don't like how it's getting its answers.	11876 
It might work some of the time, but I wouldn't have confidence that it would pick the right category if there weren't any clear indicators like keywords that I would have to go back and check.	77808 
I think it has enough accuracy. 	29455 
It was easy to use.	92873 
If my emails were about sports I could see how this model would be accurate but not sure about other topics.	69408 
I could program keywords that would separate emails and I think it does that pretty accurately as long as the keywords are present.	35003 
It is easy enough to set up words to sort emails, I don't know why ML would be different.	61948 
I think it would be helpful, but not perfect.	22413 
i dont think the model is close to 100% in guessing right.	31990 
I think it did fine.	53843 
It was accurate enough that it was worth letting it do the work	78674 
It's easy to understand,	52065 
It would be good to have a fine-tuned filter that was made that way by me, to my specifications	52071 
It seems to do an okay job. 	69984 
I think it was accurate in most cases. A few times it used wrong keywords I believe but overall the model performed well.	53675 
I think, for the most part, the model does a good job.	82848 
Out of the 10 emails the machine was only wrong on 4 of them. So I think that the machine would be able to select the majority of emails correctly. 	27433 
I think overall this model was successful at the task and did a good job.	30673 
I would be able to distinguish the two.	43243 
It seems to have high accuracy.	66672 
I think the machine was pretty accurate in it's predictions. 	95116 
im not sure how it would work for me since i dont talk about sports	38546 
It is good but it can make simple mistakes. It seems its scanning for certain words while ignoring major words that are related to the sports.	14438 
it did make a few mistakes and also it is not perfect. some emails are too vague and may lead to more mistakes overall	76420 
I think the model does a good enough job reviewing and categorizing the emails that it would be able to save me some time as long as I understood that occasional mistakes would happen.	49658 
It did a pretty good job and the importance of splitting hockey/baseball is low so errors don't bug me	37825 
I would not feel frustrated because the model does a very good job of recognizing the emails.	80642 
I think the model was pretty accurate.	78025 
I think it is pretty good, so I would be comfortable using it. Also, if it gets better through training, then I would be even more comfortable with it.	48496 
I would be hesitant until I worked with the model for a period of time	91469 
I'm not sure how it would help.	39996 
I don't think it's frustrating at all.  It seems to be working.	11101 
The model was pretty accurate. 	83048 
I would be afraid it would misjudge the email if both sports were mentioned.	41825 
I would feel a little frustrated, because it's not readily apparent why certain words were focused on. However, if I'm able to add my own words to help the model make decisions, I would feel less frustration about using it.	16269 
I just felt like there was no rhyme or reason to which words were highlighted. I get the locations words that were highlighted but I never figured out the decisions by the model.  	56430 
I don't think the model is good at discerning ambiguous content. I don't think it has mastered the ability to read between the lines to understand what the conversation is about if the topic isn't obvious. So it wouldn't be able to accurately categorize e-mail as well as a person can. It is more limited. 	52037 
It seemed to be right for the majority of the time so I wouldn't mind using it	29663 
if i was going to use a model i'd want a near-guarantee that it was correct at least 98% of the time; otherwise, what's the point of the model? i might as well just do my own research in that case.  which is why i'd never pay for a model like this.  part of sports info and stats is the satisfaction i get out of doing my own research. in my case i don't want a model. i think it would lead to lots of frustration. part of that is i'm 63.  i remember names like pat burns and buck showwalter.  younger fans wouldn't know those names.	25582 
I would feel frustrated because the model isn't 100% accurate.	87836 
I would already know my own emails and their subject matter.  I guess I don't really understand this question.	58394 
I think the model can be integrated and useful. Once integrated, improvements can be implements.	17287 
I felt it did a pretty good job at determining the difference, but not perfect. The less obvious emails could use some work - perhaps if it learns to pickup on subtle keywords when nothing more obvious is present would help.	27617 
i don't think i would like a program scanning my emails	56814 
I don't really feel one way or the other about it.  I don't care if my emails are not categorized a specific way.	94419 
I see no reason to get frustrated	54712 
A 20% error rate is too high for such a simple task	33705 
I think it works well but the errors balanced it	53422 
I think it was pretty good for the most part, for most of the emails it got correct.	86069 
it seemed to work well overall	32929 
I think it did a great job, overall. 	37158 
I don't believe it would make any more mistakes than I would, so it would just make my life easier. 	49779 
Just because it's imperfect, and I would know that.	52623 
Because some are ambiguous.	72528 
i felt all things considered it did a good job i was kind of surprised	23404 
It seems to be pretty accurate.	42782 
I do not get frustrated about things like this. I expect some errors.	63478 
A human can outperform it	17834 
It's not going to be accurate enough as it stands, but if it learns and learns quickly that opinion would likely change.	44563 
I would prefer to make my own decisions. Also, humans can decipher nuance in text.	90567 
It picks on words that have no clear meaning. This led to errors that were preventable because there were keywords in those emails that would have made the choice very simple if they had been included in the data set.	62491 
I disagree because the model made few mistakes and got most of them correct.	43252 
I think it would get better over time and learn as we go. 	56532 
It seemed to categorize them correctly without my input, and I don't follow hockey or baseball	78510 
It did really well, so I'm not worried it will be wrong	13384 
Because it sometimes seems to make arbitrary decisions and is wrong about things that should be easy to determine, and it would throw out or miscategorize some emails for sure. It seems to be right most of the time, but the basis it uses for its decisions doesn't seem sound, so I don't really know why it is as accurate as it seems to be.	43323 
I think the machine performs well on the emails it made a couple mistakes but the instructions said it would learn more over time so I think it did a good job and will only get better	86997 
It was hard to be accurate sometimes	37479 
IT WORKS 	37944 
I would not feel frustrated because on the most part it is accurate.	82590 
They were specific to a topic, but I could reply to each one. I'd do better if I knew exactly who I was replying to and had a relationship. 	18829 
I don't expect it to be perfectly accurate, so I wouldn't really feel frustrated using it since I expect it to make mistakes occasionally. 	10414 
It would do a good job because it rarely fails	90973 
It is not foolproof. Sometimes there is not enough keywords for the model to decide.	26057 
I didn't understand why it picked some of the words to make its decisions on. It did things like use the name Frank, which I can't fathom how it could make a decision based on that.	38011 
I don't understand why it chose to highlight a lot of the words it did to use in its decision making	99305 
I thought that I understood its decisions	89382 
In my own emails I tend to overwrite and try to express myself much more than usual. The model could incorrectly interpret key words that would otherwise not be related to the subject	93819 
Because I feel that the model is mostly accurate.	38348 
I think it did a good job. With a few tweaks it could be even better.	12722 
The model is fairly good and just needs a bit of fine tuning.	43602 
I think the model is quite reliable and makes very few errors.	66192 
I do not think I would feel that way	66425 
It seemed to be doing a good job. I only saw a couple that were blatantly wrong.	88474 
Unless it used a search for the subjects in the e-mails for the teams or names it would probably guess mostly incorrectly and it getting that wrong would annoy me. 	71115 
I doubt that any system would be perfect, but I also doubt there would be enough mistakes to frustrate me.	27923 
I believe that this model did fairly good job on the first 10 emails (I believe it got 7 correct) and my feedback would probably give in a much better chance at correctly categorizing the emails.  Therefore, I trust this model and even if it did not improve at all relative to its performance in the second round, its performance was acceptable in my opinion and would be only a little bit frustrating.	63856 
it's not 100% accurate and i cannot trust it because of that.	25937 
It wasn't 100% and I would rather just look through my own emails.	86192 
The model does a pretty good job for a model.	25474 
It seems to do a good job	24448 
I think I coukd teach this model to make decisions about topics and urgency	21551 
I think its pretty spot on	75669 
Not sure, maybe it wouldn't be as efficient and I would expect.	86047 
I wouldn't feel frustrated because I think the model made the majority of correct guesses. It did an okay job and I would use it to make decisions.	85740 
The model seemed to be accurate and I agreed with its decisions.	20450 
Because it got most of them right, and I would like prefer a majority to be categorized properly than do with the computer and have none categorized.	86060 
I think it does a pretty good job in general. Seems to be able to differentiate pretty well. Well enough that most would be categorized correctly.	53076 
it worked well	59029 
I would not feel frustrated because it generally seemed reliable and usually accurate.	48334 
Except for a few misinterpretations noted in the first part, the ML model was quite accurate in its ability to differentiate between hockey and baseball emails, except in a few instances as noted before i.e. the only hockey related mention was the Caps which presumably the ML model may have linked with baseball given the commonality of baseball caps. These hiccups could be ironed out but teaching the ML model how to differentiate these two instances using good data. Regardless of the room for improvement, the ML model was pretty effective and would be useful with respect to productivity. 	44365 
It seems to work well enough.	23507 
It seemed pretty effective for determining the subject.	69751 
It seems to be able to distinguish between the two, however I don't get many emails about baseball or hockey. 	58969 
I don't think it's capable enough yet, and needs more programming.	54762 
I don't have strong feelings either way	24211 
I think it did pretty good at deciding.	14725 
I don't completely trust it.	98068 
I think it was able to make the correct decision in most cases and could be accurate in most cases	95338 
it wasn't very accurate	28638 
The more I use the system the more accurate it will be at predicting.	92440 
I would have to see what it does with other subjects	35018 
I think the model is a great starting point, and there are some easy ways to improve it.	67385 
The model did a pretty good job overall.	71308 
I don't get frustrated easily. 	49560 
The model was easy to use.	54921 
It did a decent job guessing correctly	51544 
It would frustrate me because the algorithm is inexplicable. It ignores very significant words so I would always doubt it.	38915 
It was mostly correct, so I would not be frustrated.	41184 
The model is accurate enough at 90%. That is pretty decent for any sorting or ai system.	94900 
I would not feel frustrated. I think the model was good enough if it could determine the proper keywords.	67887 
It doesn't seem very sophisticated. 	65217 
In the first session, it got more right than wrong, and I think it has the capability to do better as more emails are decisioned and the program is given feedback.	11727 
I would rather make the decisions myself.  If the machine made an error it would take me just as long to fix. 	51173 
I would feel fine with it if it's fairly accurate	81347 
Because of the few errors made, this would not impact my frustration level. 	24825 
I would not because I wouldn't expect the system to be perfect.	36653 
It seemed to do pretty well from what I could see. I mean it had a 50/50 chance, but it seemed to get it right more often than not. Some of those e-mails, I even had trouble telling what they were actually about.	71019 
People even make mistakes so I expect ML to do the same.	46243 
Disagree because the model was accurate most of the time and made understanding the emails easier.	80523 
I think the model works pretty good for the most part. I think I wouldn't be too frustrated with it in the end.	28330 
The model is right almost every time and I trust it to make the right choice. The model will improve over time as it processes more data and learns from its previous mistakes.	22557 
I think the model did a pretty good job overall; I would like to be able to fine tune it but I would not be frustrated.	49332 
I didn't feel frustrated using it.	83063 
I think the machine would make the right choice more times than not.	72536 
It gets things great and is very reliable.	16979 
The model seems to learn quickly and be able to sort through and find the key words of the emails. 	25773 
it was pretty accurate and would help to sort emails.	20649 
i wouldn't feel frustrated because the model is highly efficient 	24602 
It got almost all of them right.	63743 
For the most part it was pretty accurate	72353 
I feel it got most of them right.	40677 
The model only behaves as you tell it to. Some emails can't be distinguished even by a human, so expecting the model to be perfect is silly. 	41279 
I think this would make things easier	27087 
This model is a quality predictor of a wide range of emails.	98702 
It is pretty accurate	84802 
I think it would help me and save me a lot of time, but I would also feel the need to check a lot of its work, for at least some time, so I think I would feel badly when I would inevitably find a mistake.	52767 
It was accurate more often than not	65476 
I would not feel frustrated because while not entirely accurate the model is quite reliable and can be mostly trusted upon.  	20472 
I think for the most part it did a good job of figuring it out.	53470 
I think it did a pretty good job. 	22652 
It would get most emails correct	63945 
Honestly depends on the subject since these were all sports-related.  How would the model determine from other areas of life?	56700 
I don't know	50159 
I feel like it is fairly accurate. 	23676 
It seems simple enough, somewhat the same as my gmail currently uses to sort important stuff from promotions. 	72456 
It's reasoning made no sense 9 times out of 10. It would just lead to confusion on my part.	60741 
I would not feel frustrated because I think the model does a generally fair job of correctly evaluating the emails, so my level of frustration would be lower than if the model had a much lower success rate.	95664 
It made a few errors on what seemed to me to be pretty obvious emails. 	29553 
I feel it is intuitive enough to be accurate most of the time, but still needs work	74561 
it  would not match all the time and make big mixups.	76494 
It was right	91452 
It uses words that have no power to distinguish between the subjects. It could use words like home run or strikeout for baseball and words like goal or ice for hockey. It could also use abbreviations, such as MLB for baseball and NHL for hockey, but it doesn't. It seems so random and like it doesn't have specific knowledge about either sport. 	51959 
Many of the words the model value more are not ones I would focus on for separating emails.	87517 
They were pretty good. They were not bad.	47919 
It would make mistakes only because some chosen keywords have nothing to do with either sport.	26114 
It has no substantial process to it. There are way too many ways for it to misidentify sports	37108 
had no issue with it	56194 
It seemed like it was very accurate in determining the subject of the emails.	16625 
it doesn't seem fully competent yet	99799 
It did fairly well deciding which sport the email was about	56442 
Because in the second phase/part, the computer was choosing key terms that had nothing to do with a sport.  IT was seemingly choosing random words at times and not key target words. I would be worried that my own emails would be classified/sorted incorrectly.	90525 
I think it generally does a good sorting emails between the two sports but you would definitely have to recheck.	77116 
I don't think it would be accurate enough and it would make obvious mistakes that I would be annoyed with.	92908 
I thought it did a pretty good job of picking out keywords and distinguishing the difference.	79256 
I think it would be able to decipher which emails belong where.	62850 
printed 176


trust_why
I would trust it a bit because it was usually accurate, but occasionally could be wrong, so not as good as a knowledgeable human.	19958 
the system seems to be accurate 	80507 
It's good enough	11509 
I would like to work with the model until I am confident in its judgements 	63382 
I will have to decide myself.	81902 
I think it would work correctly, with greater accuracy with more learning and input from me training it on which emails of mine fit into which category.	83661 
I would have to do a lot of work to train the model but it woukd work eventually	36333 
Too high of an error rate	95501 
It seems pretty accurate. 	93013 
It makes mistakes on these sporting events with generic information, it would do worse on emails with more nuanced topics	21960 
It only failed once in the practice	18415 
The system is very smart 	30305 
I think with training it could do just fine	38482 
I feel like it's just a good system that works well, and I assume it improves over time.	19840 
As long as nothing important is filtered I would be happy.	73587 
When terms from both sports are mentioned it confuses the system.	24586 
I would trust it because it seems to make correct decisions most of the time.	90199 
I would trust it because it knows the difference between the teams.	94111 
I think it would do a decent job.	60004 
It seems to get more right than wrong	10046 
It made mostly the right decision	38277 
It seemed to be fairly accurate with few mistakes. 	99001 
Because I Think it would learn from me 	32944 
It was just as accurate as I am, so I would have no problem using it. 	37223 
I would still want to double check since it wasn't accurate all the time.	12353 
It wasn't always right	87602 
Again 90% is decent enough.	17189 
Again I think it was more successful than I thought it would be.  	67305 
The machine was typically correct.  	90092 
I don't trust it because it doesn't seem accurate enough yet, and I'd second guess it all the time which would mean I probably spent even more time on it.	30080 
from practice i learned it's got a good percentage so i would trust it to a certain degree 	17894 
it's easy enough to correct any mistakes and it was pretty accurate overall	40702 
i have some trust in the system and if it could mark some as undecided if they do not match any terms or triggers, i would trust it more	24203 
Again, depends how literate the model is outside of sports-related knowledge.	82046 
Because it wasn't accurate enough for my tastes.	85049 
I would trust it insofar that the email was fair to the model.	41572 
It didn't make many mistakes and it would be useful to sort through a large number of emails.	27504 
it worked out about 90% of the time, good enough	21818 
Like I said before it seemed to do pretty well. Even if it was a coin flip on if it got it correct or not.	44084 
I can't understand it so I can't trust it.	62737 
It would be able to get most of the email correct	39726 
It did a good job if getting the majority of the emails correct	41163 
The model was good as long as it could find keywords.	18377 
The model is fairly reliable and can categorize the emails much quicker than the human eye.	39516 
It seems to perform well under most conditions. If it was not important to be absolutely correct (i.e. if I was just organizing personal emails), I think this system would work well for me.	21687 
It may miss some nuances but it would work good for the bulk of them.	85016 
Its very accurate and great.	80236 
It made good decisions.	62446 
The system was fairly accurate.	88732 
It seemed to be doing alright with the emails, though it might have just been random.	92391 
I think it does a good enough job of categorizing the emails correctly.  It will make some mistakes, but as long as I can accept that, I think the ML system would be helpful.	82915 
it didn't get many wrong	43284 
It is accurate enough, but I would still want to double check	83779 
It was only able to understand the easier e-mails and not the more complicated ones. 	90178 
It was mostly correct but did make a few errors.  I would gain confidence in the system if it learned from its mistakes and improved its success rate, or if there was a quick and easy way to tell it about mistakes. 	89876 
It's smart enough to get most of it right but not all of it	17614 
My own emails are filled with my own thoughts and based on the subject the model could pick up extra words that are not relevant. It could interpret them in a wrong way.	91796 
It sorted enough wrong that in volume situations I would spend more time looking for errors than it would be worth overall. Until it can get a higher accuracy rate it wouldn't be that useful.	56844 
There are some that it got wrong.	71438 
It's usually right.	32055 
The system was mostly accurate, it would just need fine-tuning and maintenance for maximum accuracy.	54533 
It proved it was capable of doing a good job.	23875 
I don't receive many emails, so I don't think I need it	11018 
it is fairly accutate	63416 
Because the model's predictions were consistent and accurate.	97775 
I would want to more feedback before implementing the model for my own emails.	95197 
i guess if it had the correct keywords to look for	23258 
I think the system needs some fine tuning.	59932 
I feel like it'd be accurate some of the time, but I don't feel that it's accurate enough for me to actually trust it to handle my own emails. 	46896 
Again, no system is perfect. I would rather judge for myself.	55585 
It's reasoning made no sense, I can't trust something that doesn't explain itself very well.	50724 
I think it did a pretty good job overall from what I saw 	77819 
Most emails containing team names and words like "pitcher" or "puck" are pretty obvious. With some good keyword management you could get it pretty accurate. 	84220 
I think it would be mostly correct but it should flag some emails as unsure if they don't contain specific keywords.	70798 
The model seemed to get most of the decisions correct	88201 
It was mostly correct, so it makes the right decisions and is therefore trustworthy.	70312 
Overall the model did do a good job. It did get a couple wrong in the phase 2, but it looked like it could decide which was which most of the time.	34653 
I do think the model was more right more times than it was wrong.	11765 
I don't trust it completely. If I'd be waiting for important emails I'd definitely not use it.	63334 
I am not sure I could trust a high percentage of emails to be correctly sorted due to the computer sometimes not picking up on key words that relate to the true subject.	89551 
really depends on the situation. Hard to say for general use unless I went in and specified keywords for the topics I am interested in.	52464 
In a majority of instances in which I was made aware of its decisions, the system made correct decisions, so I'd be inclined to put at least some degree of trust in the system to continue doing so in regards to my own emails. Any reluctance I have is the result of ambiguous emails that either give no indication of a single sport, or reveal information that is relevant to multiple sports. 	27237 
It seems accurate for a majority of the cases	85310 
Baseball and hockey emails might be easy to distinguish, but I would be skeptical if there were two categories that were very similar and use a lot of overlapping terms.	89169 
It uses random words that could be part of any sentence about anything. It also used the word Montreal to decide an email was about hockey, and the word Montreal to decide another email was about baseball. I feel like over a large number of emails it would make a lot of errors, especially with emails that had a very small number of specialized words that are unique to hockey or baseball. 	23192 
I feel confident it could sift competently though my emails	77110 
I feel like it is fairly accurate. 	81137 
I thought did a good job overall. I think it only messed up a couple in the practice rounds.	19720 
It did a good job	82368 
I think the model made more correct than incorrect choices, and I would willingly  use it to make decisions, especially when there were words and phrases that it could easily detect.	24546 
It doesn't feel as if it's using key subject matters in a search, just finding common key words and making slightly educated guesses. 	49750 
Dont think the model as is is good enough to classify emails correctly most of the time	52247 
I would be hesitant to fully rely when first using the system because I know it will make mistakes. 	95404 
From the examples I saw the machine performed well overall and seemed to get better over time, so I would trust that it would be correct when I used it.	65563 
The model needs more training	10909 
It is accurate and it keeps learning	76261 
This model was correct most of the time.	77716 
I do not see that it made many major errors in sorting and is reliable.	62129 
I would prefer to have some sort of system where there is a minimum level of confidence for the AI to make decisions and then emails below that confidence level could be filtered out for me to do manually	11006 
I thought that the machine did very well at correctly selecting the sport for most of the emails. With a little more feedback I think the machine could master this task.	18470 
I think the system had a high accuracy rate. 	46711 
It seems to be pretty accurate when it comes to emails.	88743 
I'd prefer to do it myself, but its still a useful system.	64001 
Agree because the model was accurate and I rarely felt as if I had to double check or doubt it.	69104 
It was off on some,but overall did a good job making the predictions.	72629 
I would trust it to get most right, but not all.  It did well enough.	92255 
I trust myself more	70952 
It seemed accurate from what I saw.	32748 
Again I don't think the system is very complex and there's too much room for error.	76907 
Imperfections, like lacking complete knowledge of player names, and its inability to account for email misspellings and other errors.	35158 
Just using keywords my email already does this.	44090 
As explained in detail previously, the ML model is relatively intelligent and able in doing an effective and relatively accurate job. Of course, it messed up in certain instances where the  confusion is obvious. However,room for improvement doesn't mean that it shouldn't be used until it's absolutely perfect, which in all likelihood will never happen given the elusive nature of perfection. 	44736 
It did a good job and will learn more over time so I think it will do a good job	16616 
Probably. Baseball and hockey terms aren't that close. It got it.	48230 
Some of the times they get it wrong.	19768 
It has a good track record here,	94229 
I will not trust it since it is prone to error.	40959 
I would probably trust it slightly, because even if the words it chose sometimes seemed poor indicators of the sport, it managed to get about 70% of the emails properly categorized. That would make me feel okay about it making decisions, for the most part.	74458 
I feel that there would not be very many mistakes. It also could get better with more feedback.	73603 
I think it did a decent job	64366 
The model seemed pretty accurate.	79976 
My emails are more complicated than hockey vs baseball.	12991 
I'd day it's right about 75% of the time. 	62416 
I think the model would get the majority of emails correct but not all without more training.	16976 
The model seemed to do a good job and I would believe that overtly incorrect categorizations/classifications would be corrected rather quickly based on my feedback.	72416 
For the most part yes. Its not perfect but it got most right. It would depended on how accurate emails would need to be sorted.	59867 
I don't quite understand how it made some decisions. Also, it got more wrong than I would feel comfortable with if it was to be used in a business application.	72181 
it wasn't accurate	77764 
I can't trust something that makes nearly as many mistakes as what it gets right.	29214 
From what I can see, the AI system is fairly accurate. 	41330 
It seems like it can do about as good as I can myself.	59172 
The model did not seem to have trouble picking out which sport was discussed in the emails.	82465 
only sometimes i would not just totally rely on this system to make the correct choices all the time.	62688 
I think that the model already has a good database and can learn from errors. 	27540 
The model is trustworthy and I understand how the model makes its decisions.	33171 
it does will with the information it's provided, but for ambiguous things still needs oversight.	26217 
Nothing is flawless I would expect it to make some mistakes.	70494 
It was wrong a few times	65608 
I don't think its fully reliable yet. I'll have to go through every email to make sure that there are no mistakes done.	71875 
It misses some obvious keywords	57879 
sort of the same answer i gave above.  this model showed me during this survey that it is not reliable.  it did okay but i want better than okay.  there were some bad misses.  i wouldn't trust it.  it needs to be programmed better.  i got the idea it got about 80% correct.  thats a "B minus."  not good enough.	53757 
It might or might not	47433 
It did a good job overall and I would feel comfortable using it. I'd still scan over the emails myself since I'm aware it could still use some improvement.	60426 
I think it worked just as good as any kind of software that can sort through emails.	16786 
there were only a few that made it difficult to decide which email it was talking about.	75763 
It seems to have proved itself in the current task	24843 
I don't have enough info about it.	57126 
The model has shown to be quite reliable by accurately sorting a majority of the email shown, therefore I feel that I can trust it based on its previous performances.	73414 
I think the model did a good job in distinguishing information in the emails. 	27825 
Same answer as above	43152 
It got more right than wrong and, as I said earlier, I think it has the capacity to get better.  There are strong and different keywords for each sport that it would be relatively easy for it to learn over time.	59701 
I feel that the machine would be able to classify emails based on key words effectively.	67333 
Because it makes some obvious mistakes, and because I don't trust the basis for its decision making.	68848 
I would trust it to sort emails like promotional ones but I wouldn't want it to make decisions for my personal emails. I would still like to have control over those. 	63870 
I think it would make a few mistakes but I think overall it is useful.	10082 
The model did a pretty good job overall.	24475 
It was pretty hit and miss	11303 
It was mostly right	56627 
I think the machines would be correct more times than not.	56521 
For the part, the system's predictions were correct. 	45664 
again, as above, i dont know how it would work for me at all	39704 
Because I feel that the model is mostly accurate.	14821 
I didn't notice any huge errors 	58571 
I would trust it a little. They were right most of the time.	33271 
It doesn't seem very sophisticated. 	87611 
Too many of them were wrong. It needs more learning, specially when no keywords were present.	51424 
I wouldn't trust it because it's not 100% accurate and makes mistakes. 	52830 
for the most part it made the right decisions	33255 
It got some wrong, so I wouldn't trust it until it was at nearly 100%.	69858 
Picking random words to base its decision on doesn't seem like a trustworthy system.	71258 
PERcentage wise it does well	99644 
Same reason as above. 	60036 
I agree because it is very helpful and only made a few mistakes.	80749 
it's not refined enough	43115 
It got most right, but most of the mistakes were made for highlighting the wrong keywords.	35832 
Because it was mostly accurate. I would check it periodically at first, however.	12431 
printed 176


recommend_why
I would still want people to do the job.	97758 
The model works most of the time and is mostly predictable in the results it gave.	67756 
I think it works well	64372 
It did what it was supposed to there were only a few instances where it was wrong an I think that is about as good as a person could do sorting emails.	82123 
It is able to efficiently sort emails and quickly learn the rules of what it needs to look for. 	63799 
Although there may be some mistakes at first I think that the machine could become more effective with the task and save time going though the various emails. 	11175 
It understood, but I do think human interaction matters.	88584 
The model is reliable plus it can be quite useful in the case that it judgement are better than that of humans therefore having this model can improve the efficiency of my hypothetical company.	90702 
If the model got better at it's accuracy I would, but not until then as it would disappoint. 	37211 
I felt that this experience was good.  The model wasn't too far off of its ideal performance levels and would likely be able to refine its predictive capabilities with some minor feedback.	85856 
It works basically well with some human oversight.	62140 
I would recommend the model because it is worth it to have this help and know that it will do it's job correctly.	49098 
Because having most emails categorized without the need for us to do it ourselves will save a lot of time, even though some aren't done properly.	78633 
If I thought it would be useful to them I would recommend 	50341 
I would probably recommend the model, assuming its word set is able to be updated and tweaked. That is really the crux for me, as far as whether I'd choose to recommend this. If it can evolve and expand its knowledge base over time, that could make it a useful tool for this purpose.	30669 
Because it does seem to do an efficient job of classifying emails.	60721 
Needs some refinement	47942 
no, but I would if we can choose what word this AI should scan for.	57250 
The model did make the email subject condensed and gave a sense of understanding. 	68025 
It will improve efficiency	62338 
Because it does a decent enough job	88385 
it accomplished what it set out to.	35873 
This model could save us time and does a good enough job that I would recommend it, with the caveat that like any model, it's not perfect.	53098 
It's  easy to understand.	50287 
The system is extremely smart and efficient 	27084 
It was not accurate enough that I could feel comfortable recommending it	49469 
It needs to be worked on more before I'd feel comfortable using it for my hypothetical company. 	11714 
I think it has potential to be great.	82870 
I agree that it did a good job, but it still has about a 20% error rate. I think most companies would find that high an error rate unacceptable.	45629 
Its accuracy rate isn't high enough for me to feel comfortable in recommending it.	67868 
id need FAR more data than just this snippet	71108 
There are still enough errors I would hesitate to use this.  I would want to make it better.	37441 
I wouldn't recommend it until it was better.	79038 
This model works. 75-90 percent of the emails the model made the correct choice. There should still be human supervision to correct the few emails the model incorrectly chooses.	67081 
Because I think it is accurate enough	26584 
i don't see the point in it.  a company wants to do superior work.  this model, as now constructed, does "okay" work.  i don't want a company to be okay.  i want it to be excellent and excellence can be achieved by people if they work hard enough.  anyone who wants to do the necessary research could have done better than this model.	79023 
The system was correct 90% of the time.  I think human interaction would have the same results.	74511 
it does a decent job overall and there will be errors but it can cut down on a large sum of menial labor	66585 
until it proves it can be 99.9% accurate, it's not worth using/paying for.	97245 
only if it adjusted after the first 10 emails were done by me.	66452 
I actually liked using the system.	65909 
Correct more times than not.	10055 
I think it is on the right track and could be made to be very efficient.	32916 
I would recommend the model because of it's accuracy in predicting emails.	55658 
Coworkers would likely refuse to learn how to use it	10167 
I would because the model was pretty good making predictions.	14242 
Because of the imperfections I pointed out in question 8.	18125 
This model seems to improve over time and was mostly accurate and I think it could save a lot of time for employees, so I would recommend it.	90634 
It's reliable and will help the company categorize much faster than regular humans.	95006 
It will save us time.	57995 
I would recommend this model to the hypothetical company because as noted above it has a relatively high degree of accuracy, efficacy, effectiveness, and efficiency. 	13280 
i think it's accurate enough to put to use 	12449 
It has a good level of accuracy and will only get better.	45494 
Based on what I have seen it works.	67142 
It seems to work alright now, and I think it would be easy to make it even more reliable if it were given certain training sets.	18629 
It was mostly right	98006 
I think it does a good job	30820 
I think after the initial instillation of the model it will save time. 	38010 
I think the model is probably close enough to working at a level of accuracy to make it worthwhile to use	98510 
If I got it accurate, sure. In it's current state I think the keywords could be tweaked to make it accurate enough for professional use. 	63084 
it is accurate and knowledgable	78548 
it seemed pretty reliable and like it would improve over time	75681 
It doesn't seem very sophisticated. 	21872 
Because it will clearly miscategorize items in some instances and could very easily throw out an important email.	72025 
I mean it worked pretty well with a few mistakes. overall i imagine it would do an ok job at sorting most email.	49286 
it is often correct and works on a good algorithm 	68112 
I think using this model could help speed up sorting emails with pretty high accuracy. 	79088 
I think the model has potential but needs to be improved so it can understand a conversation and know what the terms are if someone doesn't obviously mention baseball or hockey. It should also understand related names of people and terms that give clues to what the e-mail is about. 	12280 
Isn't transparent enough about how it comes to decisions.	70925 
I think it did a better than average job, and would willingly use it for myself, but would perhaps be hesitant for using it in a company unless it improved its record and could easily choose all the email subjects correctly.	16830 
I love implementing new technology and this is a very successful technology in my opinion.  I would be interested to see how it performs in the real world, in the long run. 	40408 
Even if the algorithm was ~75% accurate it would save time.	89642 
it works well enough	64859 
I feel like it is accurate enough to be of benefit to the company.	57070 
I would like to see more first	21158 
Unless it could prove to be correct all the time I could not recommend it	52838 
It is a good model	32602 
I think it would be very useful as long as there is also some manual review.	20098 
I might recommend it because it does pretty well but it would be hard to stand by it completely because it isn't 100%.	65698 
90% seems high but if the company wants more than that, this AI might not be able to pull it off on vague emails.	82233 
I think it would likely save some time.	57757 
It could save time. It would be slightly helpful.	70014 
The model did a pretty good job overall.	96467 
I think it needs more time before rolling out to a business.	88182 
It wasn't accurate enough to use in place of business	18565 
I think it did pretty well	83635 
It was extremely accurate, and at least as good as the average human.  It did a good job of selecting the right words to be able to make the right decision.	24957 
It already did good and will only improve so I would recommend it. It would help cut down on how employees send time on emails	18968 
It would need to be refined more if used in a detail oriented field but other then that it would save time for the company.	34767 
It would make some work tasks easier and free me up to do other things. 	59415 
I think it could be very useful for searching through emails. It could prove to be very beneficial.	17424 
Even though it wasn't always right, it was right most of the time so it could save time	54186 
It seems easy enough to program and maintain, had good accuracy.	92550 
It could be a good tool to save a company time and effort	54414 
It did a good job	35238 
It is a good model if it is able to find keywords. However, I would want to look at a larger sample before fully recommending it to my company.	23649 
I feel like it's not nearly reliable or advanced enough. It doesn't seem to have learned or adapted to words that would be very useful in distinguishing hockey from baseball. It's extremely unsophisticated and I imagine my superiors would be wondering why I chose such a limited model. 	89055 
Because I feel that the model is mostly accurate.	83706 
I don't know how quickly or if it could learn in order to recognize the very basics, let alone more complex situations like one of the emails that talked about both hockey and baseball leagues.	41947 
It's success rate is high.	78900 
The model would not be able to distinguish sports at an acceptable level	25489 
It needs more work.	12848 
It would depend on the employees.  I prefer to be hands on and would rather do the work myself.  However, other people have the exact opposite feelings. 	98178 
After a few weeks of trials, it would largely perform correctly.	40697 
I would be only willing to partially recommend.	22152 
I think it still needs to be improved.	89229 
It can only get better 	46546 
It seemed to be fairly accurate with few mistakes. 	66157 
It works great and is right on the money.	76315 
As stated before it does a good job of knowing what the emails are about. Some people would not even be able to figure some of the emails out. I had a hard time unless there were specific words that pertained to one sport or the other.	21319 
I would think that going back manually to check accuracy might take away from any convenience the computer might initially provide.	26868 
I think it could be modified or programmed better and if was more accurate could be a useful tool unless there are better ones out there.	58832 
It's accuracy overall was good, and it would save a lot of time in the long run, even with the occasional error where it determines something incorrectly.	84923 
It would depend on the volume of emails involved, and the success rate of the software. I think it would certainly be worth a try. 	62449 
I can't recommend something I don't understand.	15560 
The model seems to do a good job at deciphering what type of email is relevant based on keywords. In a professional setting where certain emails would need to be categorized quickly and efficiently, I believe the model could do a good job.	74022 
I think I could probably figure the model out given more time, and I believe it was more accurate than it was inaccurate. 	35733 
I feel it could be useful.	45731 
They are not 100 percent but decent	68299 
It could be a source of sorting emails especially so we could know what it was about before having to go through all manually.	28376 
The model was easy to use and easy to interpret.	12927 
The model was accurate when making decisions.	94456 
IIt was mostly correct, so I think it would be very useful.	15133 
It does a good enough job	46262 
I would not want to be responsible if the model is wrong	30479 
it would cut down on time spent sorting through emails	25677 
nothing is perfect but this would hbe helpful	13937 
I think it could make a mistake on a company scale that may cost somebody money.	19740 
It would depend on if there were any other alternatives	61071 
I would hesitate to tdo that in general 	77475 
Until there is a way where the model would not make a mistake then I would not recommend it.	24022 
I did not see many errors that the model made.	84706 
Most of the decisions seemed right to me.	17557 
I'd need to know about the company's need. 	40814 
I would wait until it worked perfectly	14232 
Based on my previous responses, I have some uncertainty as to the true accuracy of this model over the long term, so investing in such a system would require many more trials. With that said, there is sufficient evidence from the first 10 trials to think that the model could be a net positive for my hypothetical company, and so I would seek to implement it on a trial basis.	13661 
Same reason as previous answer, I think the model would get the majority of emails correct but not all without more training.	82787 
It gets more right than wrong and it has the capacity to learn.  This would save time and money at the end of the day.	75268 
It misses some obvious keywords	49456 
I would get fired for the ineffectiveness of this model	59234 
It can pick up on the right things from time to time.	24143 
I would maybe recommend it because it seems fairly accurate and reliable if it were too much work for a trained human to do similar tasks.	23264 
It seems to be pretty accurate overall.	20462 
It seems to do well enough with sports knowledge so I'd be willing to give it a try with other areas to see how well it did with those.	74111 
Depends on how accurate and important something like this would mean to the company.	37299 
it got most of the emails correct.	69130 
This model can be taught to recognize certain words and a lot of them. 	24573 
it is not nearly reliable enough making decisions to be used in business	28979 
Not enough information.	19605 
With some tweaks, I think it could work even better. But overall, it did better than guessing.	11862 
The system works and it would be useful.	36954 
i work in healthcare and there's too much to do with hipaa to worry about a program scanning our emails in this industry	43905 
I would definitely use this!	71972 
I think that it could save a lot of time. The files could be sorted so that you could pick which emails to read.	80705 
I would recommend it because I think it could help the company to be more effective and efficient.	91473 
It doesn't solve a problem with enough reliability. If something is causing as much of a problem as it's trying to fix, I see no reason to spend money on it. 	95547 
I guess it would be ok, it was right often, but I would need to run it through hundreds if not thousands of emails to see if the statistics could be lowered into the 99% range	38493 
it wasn't accurate	86132 
I would recommend this model because it is easy to use and it will help a lot. I also think it would make a few mistakes but improve over time.	34596 
it did well	58601 
Yes as long as it stops focusing on terms that aren't necessary terms like "and" and "the"	52675 
Not perfect, but pretty accurate.	11233 
Again, it needs a lot more to learn, specially when emails are ambiguos.	11009 
The model would help a company by efficiently processing emails and categorizing them. The model is trustworthy and accurate which means the company would feel comfortable using it.	48860 
Maybe good for some people but not for me.	88896 
The model is clearly underdeveloped and needs serious upgrades before it can improve its accuracy.	46085 
The same as above, needs improvement	46894 
I think it is effective enough at categorizing emails that it would be able to help employees save some time.	55508 
I don't know how useful it would be	98541 
It could be wrong sometimes	42589 
It helps managing tons of emails I guess.	54312 
Again there are too many mistakes just in the e-mails I saw.  I think it got three of them wrong which is a 30% error rate and that's too high.	30320 
I think it would be a useful tool in organization.	52837 
It was capable and would meet our needs.	58633 
I would cautiously recommend it. I would like to know a bit more about how it actually formulates it decisions, but I think from what I have seen of it. It is mostly trustworthy.	33734 
For being a system that can learn I think it is trained very well for being new.	47027 
printed 176

Process finished with exit code 0
